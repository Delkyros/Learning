# -*- coding: utf-8 -*-
"""Machine learning alura

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dbyfzrL622bksheq76RnLmR0AX-Fd6zt
"""

#exemplo de classificação usando machine learning

pig1= [0, 1, 0]
pig2= [0, 1, 1]
pig3= [1, 1, 0]


cao1= [0, 1, 0]
cao2= [0, 1, 1]
cao3= [1, 1, 1]

x_train = [pig1, pig2, pig3, cao1,cao2,cao3] #dados features
y_train = [1,1,1,0,0,0] #classes labels

#como estimar qual é cão e porco?
from sklearn.svm import LinearSVC
SEED=20
model = LinearSVC(random_state=SEED)
model.fit(x_train, y_train)

animal_misterioso = [1,1,1]
pred_animal_misterioso = model.predict([animal_misterioso])
if pred_animal_misterioso==0:
  print('É um cachorro')
else:
  print('É um porco')

animal_misterioso1 = [1,1,1]
animal_misterioso2 = [1,1,0]
animal_misterioso3 = [0,1,1]
x_test= [animal_misterioso1, animal_misterioso2, animal_misterioso3]#valores a serem classificados
y_test = [0,1,1] #valores reais

pred_animal_misterioso = model.predict(x_test)
for i in pred_animal_misterioso:
  if i==0:
    print('É um cachorro')
  else:
    print('É um porco')

"""O correto seria cachorro, porco e porco. houve um erro do algoritmo ao classificar os animais misteriosos, ou seja 66% de acurácia."""

acertos = (pred_animal_misterioso == y_test).sum()
total = len(x_test)
acuracia = (acertos/total*100)
print('Acuracia é de %.2f' % acuracia + '%')

"""Bonito, mas o sklearn tem todo esse código numa função só."""

from sklearn.metrics import accuracy_score
acc = (accuracy_score(y_test, pred_animal_misterioso)*100)
print('Acuracia é de %.2f' % acc + '%')

"""# Aula com outros dados

A uri são dados relacionados a sites, se possuem home, se funcionam, se possuem contatos e se estão a venda. Os dados estão dispostos em uma matriz booleana.
"""

import pandas as pd
uri = "https://gist.githubusercontent.com/guilhermesilveira/2d2efa37d66b6c84a722ea627a897ced/raw/10968b997d885cbded1c92938c7a9912ba41c615/tracking.csv"
dados = pd.read_csv(uri)
dados.head()

#traduzindo o nome das features
rename_map = {
    'home': 'principal',
    'how_it_works': 'funciona?',
    'contact': 'contato',
    'bought': 'comprado'
}

dados.rename(columns=rename_map, inplace=True)

x = dados.drop('comprado', axis=1)
y = dados.comprado

"""Para um treinamento com melhores predições é importante separar o treino do teste."""

treino_x= x[:75]
treino_y= y[:75]
teste_x= x[75:]
teste_y= y[75:]
print(f'Treinaremos com n={len(treino_x)} para x e testaremos com n={len(teste_y)}')

import numpy as np
SEED=20
np.random.seed(SEED)

model.fit(treino_x, treino_y)
pred = model.predict(teste_x)
acc = (accuracy_score(teste_y, pred)*100)
print('Acuracia é de %.2f' % acc + '%')

"""Se definirmos a seed nop numpy automaticamente vamos definir a ssed para todos os modelos do sklearn.

Há também uma forma de separar usando o modelo próprio do sklearn.
"""

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)

"""O código acima realiza a separação do treino e do teste utilizando um modelo do sklearn feito para esse fim."""

model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print('Acuracia é de %.2f' % acc + '%')

from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print('Acuracia é de %.2f' % acc + '%')

"""Perceba que ao utilizar o mesmo código, obtemos acc's diferentes. Isso ocorre devido ao estado aleatório do modelo (random_state)."""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=SEED)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print('Acuracia é de %.2f' % acc + '%')

"""Definindo uma seed, ou alterando o parametro random_state para um mesmo valor, temos uma separação de teste e treino fixada na aleatoriedade gerada pela semente, ou SEED=20. Assim temos sempre a mesma acc.

## Verificando a separação
"""

y_train.value_counts()

y_test.value_counts()

"""Perceba que a proporção de valores 0 e 1 não bate para o teste e para o treino. isso tendencia o treino de acordo com a classificação que o 0 e o 1 define. se 1 é compra, por exemplo, no teste há muito mais compradores do que no treino. Isso tendencia o modelo ao viés de que mais compras sempre serão feitas."""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print('Acuracia é de %.2f' % acc + '%')

y_train.value_counts()

y_test.value_counts()

"""Agora temos uma mesma proporção e para este dataset,nao houve mudanças na acc, mas geralmente há uma alteração positiva ao ter uma proporção igual entre teste e treino. Claro que strafity só se aplica quando as classes (0, ou 1), possuem um número grande de repetições.

# Novo projeto
"""

uri = "https://gist.githubusercontent.com/guilhermesilveira/1b7d5475863c15f484ac495bd70975cf/raw/16aff7a0aee67e7c100a2a48b676a2d2d142f646/projects.csv"
dados = pd.read_csv(uri)
dados.head()

"""Para este dataset é possível criar algumas features de interesse. Como a feature finished que é o oposto da unfinished"""

troca={0:1, 1:0}
dados['finished'] = dados.unfinished.map(troca)
dados.head(10)

"""Visualização usando seaborn."""

import seaborn as sns
sns.scatterplot(x='expected_hours', y='price',hue='finished', data=dados)

sns.relplot(x='expected_hours', y='price',col='finished', hue='unfinished', data=dados)

"""Visualmente, parece que em algum valor/hora os projetos são finalizados."""

x=dados[['expected_hours',	'price']]
y=dados['finished']
model = LinearSVC()

x_train, x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

"""Acc não está tão elevada assim, mas isso não significa que o modelo é ruim. Temos que compara-lo com algum outro para verificar se a acc atual é de fato "ruim"."""

import numpy as np
my_pred = np.ones(540)
acc = (accuracy_score(y_test, my_pred)*100)
print('Acuracia é de %.2f' % acc + '%')

"""A previsão de base (baseline) considerando somente a classe 1 esta próxima da previsão do algoritmo. Com isso, podemos inferir que o modelo não é adequado, ou é ruim para estes dados.

## Melhorando o modelo
"""

x_min = x_test.expected_hours.min()
x_max = x_test.expected_hours.max()
y_min = x_test.price.min()
y_max = x_test.price.max()

pixel = 100
x_ax =np.arange(x_min, x_max, (x_max-x_min)/pixel)
y_ax =np.arange(y_min, y_max, (y_max-y_min)/pixel)
xx, yy = np.meshgrid(x_ax, y_ax)
dots = np.c_[xx.ravel(), yy.ravel()]
z = model.predict(dots)
z = z.reshape(xx.shape)

import matplotlib.pyplot as plt
plt.contourf(xx, yy, z, alpha=0.3)
plt.scatter(x_test.expected_hours, x_test.price, c=y_test, s=1)

"""A reta que define a separação das classes 0 e 1 estão muito mal posicionada e consequentemente não explica a diferença entre as classes. Uma reta não iria separar os dados neste dataset.

## Testando Support vector classification (SVC)
"""

from sklearn.svm import SVC

x=dados[['expected_hours',	'price']]
y=dados['finished']
model = SVC()

x_train, x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

x_min = x_test.expected_hours.min()
x_max = x_test.expected_hours.max()
y_min = x_test.price.min()
y_max = x_test.price.max()

pixel = 100
x_ax =np.arange(x_min, x_max, (x_max-x_min)/pixel)
y_ax =np.arange(y_min, y_max, (y_max-y_min)/pixel)
xx, yy = np.meshgrid(x_ax, y_ax)
dots = np.c_[xx.ravel(), yy.ravel()]
z = model.predict(dots)
z = z.reshape(xx.shape)

import matplotlib.pyplot as plt
plt.contourf(xx, yy, z, alpha=0.3)
plt.scatter(x_test.expected_hours, x_test.price, c=y_test, s=1)

"""Por termos valores de elevada variação e escala os modelos não conseguem predizer com uma acuracia aceitável. Será necessário realizar uma normalização dos dados."""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(x_train)

from sklearn.svm import SVC

x=dados[['expected_hours',	'price']]
y=dados['finished']
model = SVC()

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)

scaler.fit(raw_x_train)

x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)

model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

"""Agora tivemos um aumento expressivo da acc."""

data_x = x_test[:,0]
data_y = x_test[:,1]

x_min = data_x.min()
x_max = data_x.max()
y_min = data_y.min()
y_max = data_y.max()

pixel = 100
x_ax =np.arange(x_min, x_max, (x_max-x_min)/pixel)
y_ax =np.arange(y_min, y_max, (y_max-y_min)/pixel)
xx, yy = np.meshgrid(x_ax, y_ax)
dots = np.c_[xx.ravel(), yy.ravel()]
z = model.predict(dots)
z = z.reshape(xx.shape)

import matplotlib.pyplot as plt
plt.contourf(xx, yy, z, alpha=0.3)
plt.scatter(data_x, data_y, c=y_test, s=1)

"""Em comparação com os outros gráficos claramente,temos uma separação de dois grupos de forma mais correta.

# Outro algoritmo para um problema diferente
"""

uri = "https://gist.githubusercontent.com/guilhermesilveira/4d1d4a16ccbf6ea4e0a64a38a24ec884/raw/afd05cb0c796d18f3f5a6537053ded308ba94bf7/car-prices.csv"
dados = pd.read_csv(uri)
map = {'yes':1, 'no':0}
dados['sold']=dados['sold'].map(map)
dados['age'] = dados['model_year'].max()-dados['model_year']
dados = dados.drop(columns = ['Unnamed: 0', 'model_year'], axis=1)
dados.head()

x =  dados[['price', 'age', 'mileage_per_year']]
y = dados['sold']

model = LinearSVC()

x_train, x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)
model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

from sklearn.dummy import DummyClassifier
dummy = DummyClassifier()

dummy.fit(x_train, y_train)
pred = dummy.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

"""Agora usamos uma baseline do próprio sklearn. É possível ainda usar o dummy para calcular a acc."""

acc = (dummy.score(x_test ,y_test)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

scaler = StandardScaler()
scaler.fit(x_train)

model = SVC()

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)

scaler.fit(raw_x_train)

x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)

model.fit(x_train, y_train)
pred = model.predict(x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

"""# Usando arvores de decisão

Para conseguir entender melhor decisão de classificação. É comum utilizar arvores de decisão, que são modelos não blackbox, ou seja, permitem observar o por que da decisão e classificação realizada.
"""

from sklearn.tree import DecisionTreeClassifier

scaler = StandardScaler()
scaler.fit(x_train)

model = DecisionTreeClassifier(max_depth=3)

raw_x_train, raw_x_test, y_train, y_test = train_test_split(x, y,
  test_size=0.25, random_state=SEED, stratify =y)
'''
scaler.fit(raw_x_train)

x_train = scaler.transform(raw_x_train)
x_test = scaler.transform(raw_x_test)'''#não é necessário para arvores de decisão

model.fit(raw_x_train, y_train)
pred = model.predict(raw_x_test)
acc = (accuracy_score(y_test, pred)*100)
print(f'Treinaremos com n={len(x_train)} para x e testaremos com n={len(x_test)}')
print('Acuracia é de %.2f' % acc + '%')

from sklearn.tree import export_graphviz
import graphviz
features=x.columns
dot_data = export_graphviz(model, out_file=None,
                           filled=True, rounded=True,
                           feature_names = features,
                           class_names =['Não', 'Sim'] )

graph = graphviz.Source(dot_data)
graph

