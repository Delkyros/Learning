# -*- coding: utf-8 -*-
"""PCA applied to districts.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zts2ibKoPVzqnAUVT7z7WJ7JM55U2PaK
"""

import pandas as pd

"""Objetivo: Ordenar qual dos distritos é o melhor para se morar, utilizando o PCA e os fatores gerados pela modelagem dos dados.


"""

data = pd.read_csv('distritos_sp.csv')
data.head()

"""# Matriz de correlação"""

data.info()

"""Somente valores númericos podem ser usados para correlação e portanto para uma PCA."""

data_num= data.drop(['cod_ibge', 'distritos'], axis=1)
#matriz de correlação
data_cor = data_num.corr()
data_cor

"""Quanto maior os valores absolutos das correlações mais impactantes elas serão nos fatores do PCA. Se as correlações forem baixas não há necessidade de aplicar o PCA.

## Avaliando as correlações para PCA
"""

!pip install factor_analyzer

"""## Teste Kaiser-Meyer-Olkin (KMO)

Teste realizado para saber se os dados possuem consistência necessária para terem uma variancia comum. Se os dados variam num mesmo padrão é possível gerar um fator que explique melhor o comportamento deles. Essa estatística varia de 0 a 1 e quanto mais próximo de 1, maior  são as correlações de Pearsom.
"""

from factor_analyzer.factor_analyzer import calculate_kmo

kmo_var, kmo = calculate_kmo(data_num)
print( f'O kmo das variáveis é de {kmo_var}\n\n Enquanto que o kmo={kmo}')

"""Os kmo estão todos elevados (acima de 0,5), assim como o kmo geral para as variáveis utilizadas. Isso indica que um outro teste deve ser feito para confirmar se o PCA deve ser realizado.

## Teste de esferacidade de Bartlett

Este teste nos diz se as variáveis realmente são diferentes de uma matriz de identidade. Utilizando a confirmação destes dois testes, podemos efetuar um PCA, com mais certeza que os fatores irão explicar a variação dos dados e até memso indicar qual é o melhor distrito por exemplo.
"""

from factor_analyzer.factor_analyzer import calculate_bartlett_sphericity

qui_, pvalue = calculate_bartlett_sphericity(data_num)
print( f'O qui² das variáveis é de {qui_}\n\n Enquanto que o pvalue={pvalue}')

"""Valor de p menor do que 0,05, podemos ter certeza da diferença da matriz identidade e da matriz de correlação dos dados.

Assim, seguimos para o teste de PCA.

## Escalonando os dados usando z score

O z score é a redução da média e divisão pelo desvio padrão de cada amostra para cada variável. Assim obteremos dados dentro de uma mesma escala para podermos executar a PCA.
"""

from sklearn.preprocessing import StandardScaler

data_num_col = data_num.columns #salvando as colunas em uma variável
scaler = StandardScaler()
data_num_ = scaler.fit_transform(data_num)
data_num_scaled= pd.DataFrame(data_num_, columns = data_num_col)
data_num_scaled

"""# Executando PCA"""

from sklearn.decomposition import PCA

n_factors = data_num_scaled.shape[1] #variáveis totais
pca = PCA(n_components=n_factors)
pca.fit(data_num_scaled)

"""## Explorando os fatores"""

explain = pca.explained_variance_ratio_

for i in explain:
  print(f'{i*100}%')

"""Aqui percebemos que entre os fatores gerados pela PCA o primeiro é o que mais explica a variação dos dados."""

import plotly.express as px
import numpy as np

factors = [f'F{i+1}'for i in range(n_factors)]
factors

import plotly.express as px
import numpy as np

fig = px.bar(x=factors, y=pca.explained_variance_ratio_,
             text=np.around(pca.explained_variance_ratio_, decimals=2),
             title='Scree Plot')

fig.update_layout(
    yaxis={'title': 'Porcentagem de variância explicada', 'tickfont': {'size': 15}},
    xaxis={'title': 'Fatores', 'tickfont': {'size': 15}},
    title={'text': 'Scree Plot', 'font': {'size': 25}}
)

fig.show()

factors_variance_sum = [sum(pca.explained_variance_ratio_[0:i+1]) for i in range(n_factors)]
factors_variance_sum

fig = px.bar(x=factors, y=factors_variance_sum,
             text=np.around(factors_variance_sum, decimals=2),
             title='Scree Plot')

fig.update_layout(
    yaxis={'title': 'Porcentagem de variância explicada', 'tickfont': {'size': 15}},
    xaxis={'title': 'Fatores', 'tickfont': {'size': 15}},
    title={'text': 'Scree Plot', 'font': {'size': 25}}
)

fig.show()

"""Utilizando somente F1 e F2 é possível explicar 68% dos distritos. Usando F3 além dos outros dois anteriores podemos explicar 79% da variãncia dos dados. Seria interessante saber qual desses fatores explica mais variáveis."""

pca.explained_variance_ratio_ * n_factors

"""O primeiro fator (autovalor) explica praticamente 5 das 9 variáveis, ou seja ele é muito importante para a modelagem que estamos fazendo."""

autovalues = pca.explained_variance_ratio_ * n_factors

"""## Quantos fatores iríamos necessitar para explicar os dados?"""

#realizando teste da raiz latente

selected_factors = ['fator selecionado' if autovalue> 1 else'fator não selecionado' for autovalue in autovalues]
selected_factors

fig = px.bar(x= range(1,10), y = autovalues, text= np.around(autovalues, decimals=2),
             title = 'Scree Plot', color = selected_factors)
fig.update_layout(yaxis={'title': 'Quantidade de variáveis explicadas', 'tickfont':{'size':15}},
                  xaxis={'title': 'Autovalue', 'tickfont':{'size':15}},
                  title = {'font': {'size':15}})
fig.show()

resumo = pd.DataFrame({'Factor': factors, 'Autovalues': autovalues, 'Explained variance': pca.explained_variance_ratio_, 'Sum of Variances':factors_variance_sum})
resumo

"""## A importância dos autovetores"""

pd.DataFrame(pca.components_, columns = data_num_col, index=[f'Autovector {i+1}' for i in range(n_factors)])

"""Obtendo as cargas fatoriais..."""

root_autovalues = np.sqrt(autovalues)
cargas = pd.DataFrame(pca.components_.T * root_autovalues, columns= factors, index = data_num_col)
cargas

resumo_cargas = cargas[['F1', 'F2']].copy()
resumo_cargas

fig = px.scatter(cargas, x= 'F1', y='F2', text=cargas.index)
fig.update_traces(textposition ='top center')
fig.show()

"""Percebe-se que as variáveis renda, quota, escolaridade e idade estão fortemente correlacionadas positivamente com F1. Em contra partida, mortalidade, causext, txcresc e favel estão menos correlacionadas positivamente com F1 e mais próximas de F2. A variável denspop não possui muita influência em ambos os fatores F1 e F2.

## Verificando a comunalidade
"""

resumo_cargas['comunalidade'] = (resumo_cargas ** 2).sum(axis=1)
resumo_cargas

"""A comunalidade define o quanto que a utilização de n fatores explica a variância das variáveis utilizadas. Utilizando somente F1 e F2 pode-se explicar 82% da variância entre a renda dos distritos e asism por diante.

# Obtendo os fatores principais
"""

#componentes principais a serem usados
pca2 = PCA(n_components=2)
pd.DataFrame(pca2.fit_transform(data_num_scaled), columns = ['F1', 'F2'])

"""Para obtenção dos scores fatoriais é ncessário realizar a seguinte operação."""

fatorial_score =  np.zeros(pca.components_.shape)
for i in range(len(pca.components_)):
  fatorial_score[i]= pca.components_[i]/root_autovalues[i]

fatorial_score

F1 = np.zeros(data_num_scaled.shape[0])
for i, component in enumerate(pca.feature_names_in_):
  F1+= fatorial_score[0][i] * data_num_scaled[component]
F1

F2 = np.zeros(data_num_scaled.shape[0])
for i, component in enumerate(pca.feature_names_in_):
  F2+= fatorial_score[1][i] * data_num_scaled[component]
F2

fatorial_data = data[['cod_ibge', 'distritos']].copy()
fatorial_data['F1'] = F1
fatorial_data['F2'] = F2
fatorial_data

# adicionando aos dados originais
data['F1'] = F1
data['F2'] = F2
data

"""# Ranqueamento dos distritos"""

fig = px.scatter(cargas, x= 'F1', y='F2', text=cargas.index)
fig.update_traces(textposition ='top center')
fig.show()

"""Novamente, utilizando este gráfico podemos inferir que os distritos de melhor qualidade são os que possuem maiores valores de renda, quota, escolaridade e idade, pois estes afetam positivamente o componente 1, ou F1. Os distritos com valores mais elevados de mortalidade, causaext, txcresc e favel, menor será o valor de F1. A feature denspop é inversamente proporcional ao F2, portanto ele não afeta F1. Pode ocorre cos componentes estarem todos numa mesma região, mas por sabermos por exemplo que mortalidade é ruim, o seu valor deve ser invertido, multiplicando o mesmo por -1."""

fatorial_data['Rankings'] = fatorial_data['F1'] * pca.explained_variance_ratio_[0] + fatorial_data['F2'] * pca.explained_variance_ratio_[1]
fatorial_data.sort_values('Rankings', ascending =False)

data['Rankings'] = fatorial_data['Rankings']
data

"""Podemos confirmar então, baseando-se nos componentes principais 1 e 2 que o melhor distrito é o Jardim Paulista e o pior distrito é o Marsilac. Para melhor visualizar os dados usarei um heatmap com a biblioteca geopandas."""

!pip install geopandas

import geopandas as gpd
data_map = gpd.read_file('/content/SIRGAS_SHP_distrito.shp')
data_map.set_crs(epsg = 31983, inplace=True)

!pip install unidecode

from unidecode import unidecode
data = data.sort_values('cod_ibge')

district_names = [unidecode(districts).upper() for districts in data['distritos']]
data['nome_distrito'] = district_names

data_map = data_map.sort_values('ds_codigo')
district_diff = data['nome_distrito'].values != data_map['ds_nome'].values
district_diff.sum()

data[district_diff]

data_map[district_diff]

data.replace({'SARCOMA':'SACOMA', 'Sarcomã': 'Sacoma'}, inplace=True)

data[district_diff]

data_complete = data_map.merge(data, left_on='ds_nome', right_on='nome_distrito')

"""#Visualização dinâmica"""

!pip install --upgrade folium
import folium

import matplotlib.pyplot as plt

#pegando o ponto central de cada poligono nos districos
data_complete['coords'] =  data_complete['geometry'].apply(lambda x: x.representative_point().coords[0])

!pip install mapclassify
import mapclassify

base = data_complete.explore(column ='Rankings',
                      cmap= 'seismic_r',
                      tooltip = 'distritos',
                      tooltip_kwds = dict(label =False),
                      name = 'São Paulo district names')
folium.TileLayer('Open Street Map').add_to(base)
folium.TileLayer('Stamen Terrain').add_to(base)
folium.TileLayer('cartodbpositron').add_to(base)
folium.TileLayer('Stamen Toner').add_to(base)
folium.LayerControl().add_to(base)
base

"""Usando o ranking do PCA e o gráfico anterior, podemos perceber que os distritos com maiores valores de mortalidade, causaext, txcresc e favel e consequentemente menores valores para o componente 1, tem cores vermelhas e estão na periferia da capital São Paulo do estado de São Paulo. Isso demonstra que os componenetes principais utilizados descrevem o que normalmente se aceita de capitais. Em que a periferia é o local menos valioso para se morar, por exemplo."""

base.save('SP_rankings.html')